# analysis_notebook.ipynb

import pandas as pd
from pycaret.clustering import load_model, predict_model
import csv
import re
import urllib.parse

# Load the trained K-Means model
kmeans_model = load_model('kmeans_model')

# Define SQL keywords globally
sql_keywords = [
    'SELECT', 'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 'TRUNCATE',
    'UNION', 'FROM', 'WHERE', 'AND', 'OR', 'LIKE', 'BETWEEN', 'IN', 'JOIN', 'ON', 'GROUP BY', 'ORDER BY', 'HAVING', 'LIMIT'
]

def analyze_request(method, url, headers, body_params, response_status, response_time, sql_keywords):
    '''
    Analyzes the HTTP request and extracts features related to common attacks.
    '''
    features = {
        'method': method,
        'path': url,
        'headers': str(headers),
        'body': '',
        'body_length': 0,
        'num_commas': 0,
        'num_hyphens': 0,
        'num_brackets': 0,
        'num_quotes': 0,
        'num_double_quotes': 0,
        'num_slashes': 0,
        'num_braces': 0,
        'num_spaces': 0,
        'has_sql_keywords': 0,
        'has_xss_payload': 0,
        'has_csrf_token': 0,
        'response_status': response_status,
        'response_time': response_time
    }

    uid_value = None
    if isinstance(body_params, list):
        for param in body_params:
            if isinstance(param, dict) and param.get('name') == 'uid':
                uid_value = param.get('value')
                break

    if uid_value:
        features['body'] = uid_value
        features['body_length'] = len(uid_value)
        features['num_commas'] = uid_value.count(',')
        features['num_hyphens'] = uid_value.count('-')
        features['num_brackets'] = uid_value.count('(') + uid_value.count(')')
        features['num_quotes'] = uid_value.count("'")
        features['num_double_quotes'] = uid_value.count('"')
        features['num_slashes'] = uid_value.count('/')
        features['num_braces'] = uid_value.count('{') + uid_value.count('}')
        features['num_spaces'] = uid_value.count(' ')
        features['has_sql_keywords'] = int(any(keyword.lower() in uid_value.lower() for keyword in sql_keywords))

    xss_patterns = [
        r'<script', r'alert\(', r'\(alert\(', r'</script>', r'document\.cookie',
        r'eval\(', r'window\.location', r'setTimeout\(', r'setInterval\(',
        r'execCommand', r'innerHTML', r'outerHTML', r'document\.write',
        r'XMLHttpRequest\.open', r'FormData\.append', r'document\.getElementById',
        r'document\.createElement', r'document\.execCommand', r'window\.open',
        r'window\.eval', r'window\.setTimeout', r'window\.setInterval',
        r'document\.URL', r'location\.href', r'location\.search',
        r'document\.referrer', r'navigator\.sendBeacon', r'importScripts', r'`'
    ]
    features['has_xss_payload'] = detect_xss_payload(url.lower(), str(headers), xss_patterns)

    csrf_keywords = ['csrf_token', 'anti_csrf_token', 'xsrf_token']
    csrf_pattern = r'\b({})\b'.format('|'.join(csrf_keywords))
    features['has_csrf_token'] = int(any(re.search(csrf_pattern, str(headers).lower()) for key in csrf_keywords))

    return features

def detect_xss_payload(url, headers, xss_patterns):
    decoded_url = urllib.parse.unquote(urllib.parse.unquote(url))
    for pattern in xss_patterns:
        if re.search(pattern, decoded_url, re.IGNORECASE) or re.search(pattern, headers, re.IGNORECASE):
            return 1
    return 0

def classify_and_check_intrusion(features):
    features_df = pd.DataFrame([features])
    clustered_data = predict_model(kmeans_model, data=features_df)
    new_cluster = clustered_data['Cluster'].iloc[0]

    # Load the full dataset with assigned clusters
    clustered_data_df = pd.read_csv('clustered_results_with_features.csv')
    cluster_counts = clustered_data_df['Cluster'].value_counts()

    if cluster_counts[new_cluster] < cluster_counts.max():
        return new_cluster, True
    return new_cluster, False

# Example request
method = 'GET'
url = 'http://testfire.net/default.aspx'
headers = {'User-Agent': 'Mozilla/5.0'}
body_params = [{'name': 'uid', 'value': '1 OR 1=1'}]
response_status = 200
response_time = 150

features = analyze_request(method, url, headers, body_params, response_status, response_time, sql_keywords)
new_cluster, is_intrusion = classify_and_check_intrusion(features)

print(f"Request classified to cluster: {new_cluster}")
print(f"Intrusion detected: {is_intrusion}")

# Add the new request to the CSV file
features['Cluster'] = new_cluster
features['nature'] = 'new req'
with open('clustered_results_with_features.csv', 'a', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=list(features.keys()))
    writer.writerow(features)
